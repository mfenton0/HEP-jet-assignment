{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2 for 1 sigma =  1.0012840694690475\n",
      "chi2 for 2 sigma =  3.981594462262515\n",
      "chi2 for 3 sigma =  8.807468393511947\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from collections import defaultdict\n",
    "from scipy import integrate\n",
    "from scipy.stats import chi2\n",
    "from iminuit import minimize, Minuit\n",
    "print('chi2 for 1 sigma = ', chi2.isf(1-0.683, 1, loc=0, scale=1))\n",
    "print('chi2 for 2 sigma = ', chi2.isf(1-0.954, 1, loc=0, scale=1))\n",
    "print('chi2 for 3 sigma = ', chi2.isf(1-0.997, 1, loc=0, scale=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed the bins, colors, mass arr, and labels for all plots.\n",
    "bins_min, bins_max, bins_w = 120, 230, 1\n",
    "bins = np.arange(bins_min, bins_max+1, bins_w)\n",
    "bins_mid = bins[:-1]+bins_w/2\n",
    "bins_dense = np.linspace(bins_min, bins_max, 1000)\n",
    "\n",
    "mass = [170, 171, 172, 173, 174, 175, 176]\n",
    "top_mass_dense = np.linspace(170, 176, 1000)\n",
    "top_mass_chi2 = np.linspace(166, 180, 1000)\n",
    "sudo_bins = np.arange(166, 180, 0.2)\n",
    "sudo_bins_dense = np.linspace(166, 180, 1000)\n",
    "\n",
    "loglikeli_cut = -75\n",
    "marginal_prob_cut = 0.2\n",
    "\n",
    "sudo_event = 10000\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "state_labels = ['Unmatched', 'Incorrect', 'Correct']\n",
    "langau_fit_labels = ['Mean of Landau', 'Variance of Landau', 'Mean of Gaussian', 'Variance of Gaussian', 'Fraction of Gaussian']\n",
    "two_gau_fit_labels = ['Mean of  first Gaussian', 'Variance of first Gaussian', 'Mean of  second Gaussian', 'Variance of second Gaussian', 'Fraction of second Gaussian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reco_top_mass(h5py_file, target): # Target is spanet or klfitter\n",
    "    dic = {}\n",
    "\n",
    "    #Load pt, eta, phi, and mass from file. Where q1, q2 and b are the index.\n",
    "    q1 = np.array([[i] for i in h5py_file[target + '/right_target/q1'][:]])\n",
    "    dic['q1_pt'] = np.take_along_axis(h5py_file['jet_features/pt'][:], q1, axis=1).flatten()\n",
    "    dic['q1_eta'] = np.take_along_axis(h5py_file['jet_features/eta'][:], q1, axis=1).flatten()\n",
    "    dic['q1_phi'] = np.take_along_axis(h5py_file['jet_features/phi'][:], q1, axis=1).flatten()\n",
    "    dic['q1_mass'] = np.take_along_axis(h5py_file['jet_features/mass'][:], q1, axis=1).flatten()\n",
    "\n",
    "    q2 = np.array([[i] for i in h5py_file[target + '/right_target/q2'][:]])\n",
    "    dic['q2_pt'] = np.take_along_axis(h5py_file['jet_features/pt'][:], q2, axis=1).flatten()\n",
    "    dic['q2_eta'] = np.take_along_axis(h5py_file['jet_features/eta'][:], q2, axis=1).flatten()\n",
    "    dic['q2_phi'] = np.take_along_axis(h5py_file['jet_features/phi'][:], q2, axis=1).flatten()\n",
    "    dic['q2_mass'] = np.take_along_axis(h5py_file['jet_features/mass'][:], q2, axis=1).flatten()\n",
    "\n",
    "    b = np.array([[i] for i in h5py_file[target + '/right_target/b'][:]])\n",
    "    dic['b_pt'] = np.take_along_axis(h5py_file['jet_features/pt'][:], b, axis=1).flatten()\n",
    "    dic['b_eta'] = np.take_along_axis(h5py_file['jet_features/eta'][:], b, axis=1).flatten()\n",
    "    dic['b_phi'] = np.take_along_axis(h5py_file['jet_features/phi'][:], b, axis=1).flatten()\n",
    "    dic['b_mass'] = np.take_along_axis(h5py_file['jet_features/mass'][:], b, axis=1).flatten()\n",
    "    \n",
    "    # px = pt*cos(phi)\n",
    "    # py = pt*sin(phi)\n",
    "    # pz = pt*sinh(eta)\n",
    "    # E  = sqrt(m**2 + px**2 + py**2 + pz**2)*JSF\n",
    "    dic['px1'] = dic['q1_pt']*np.cos(dic['q1_phi'])\n",
    "    dic['py1'] = dic['q1_pt']*np.sin(dic['q1_phi'])\n",
    "    dic['pz1'] = dic['q1_pt']*np.sinh(dic['q1_eta'])\n",
    "    dic['E1'] = np.sqrt(dic['q1_mass']**2+dic['px1']**2+dic['py1']**2+dic['pz1']**2)\n",
    "\n",
    "    dic['px2'] = dic['q2_pt']*np.cos(dic['q2_phi'])\n",
    "    dic['py2'] = dic['q2_pt']*np.sin(dic['q2_phi'])\n",
    "    dic['pz2'] = dic['q2_pt']*np.sinh(dic['q2_eta'])\n",
    "    dic['E2'] = np.sqrt(dic['q2_mass']**2+dic['px2']**2+dic['py2']**2+dic['pz2']**2)\n",
    "\n",
    "    dic['bx'] = dic['b_pt']*np.cos(dic['b_phi'])\n",
    "    dic['by'] = dic['b_pt']*np.sin(dic['b_phi'])\n",
    "    dic['bz'] = dic['b_pt']*np.sinh(dic['b_eta'])\n",
    "    dic['bE'] = np.sqrt(dic['b_mass']**2+dic['bx']**2+dic['by']**2+dic['bz']**2)\n",
    "    \n",
    "    # M = sqrt((m1+m2)**2 + (px1+px2)**2 + (py1+py2)**2 + (pz1+pz2)**2)\n",
    "    dic['reconstructed_top_mass'] = np.sqrt((dic['E1']+dic['E2']+dic['bE'])**2\n",
    "                    - (dic['px1']+dic['px2']+dic['bx'])**2\n",
    "                    - (dic['py1']+dic['py2']+dic['by'])**2\n",
    "                    - (dic['pz1']+dic['pz2']+dic['bz'])**2)\n",
    "\n",
    "    \"\"\"\n",
    "    cuts\n",
    "    100 < reco_m_top < 300\n",
    "    additional cuts (same as CMS)\n",
    "    \"\"\"\n",
    "    # Caululate delR\n",
    "    # Caululate delR\n",
    "#     lepton_eta = h5py_file['lepton_features/eta'][:]\n",
    "#     lepton_phi = h5py_file['lepton_features/phi'][:]\n",
    "#     jet_eta = h5py_file['jet_features/eta'][:]\n",
    "#     jet_phi = h5py_file['jet_features/phi'][:]\n",
    "#     del_eta = np.array([jet_eta[i, :4] - lepton_eta[i] for i in range(len(jet_eta))])\n",
    "#     del_phi = np.abs([jet_phi[i, :4] - lepton_phi[i] for i in range(len(jet_eta))])\n",
    "#     del_phi = np.where(del_phi < np.pi, del_phi, 2*np.pi-del_phi)\n",
    "#     delR = np.sqrt(del_eta**2 + del_phi**2)\n",
    "\n",
    "    # cuts\n",
    "    # pid 11 is electron, 13 is muon.\n",
    "#     cut_lepton_pt = np.logical_or(\n",
    "#                         np.logical_and(h5py_file['lepton_features/pt'][:] > 26, h5py_file['lepton_features/pid'][:] == 13),\n",
    "#                         np.logical_and(h5py_file['lepton_features/pt'][:] > 29, h5py_file['lepton_features/pid'][:] == 11))\n",
    "#     cut_lepton_eta = np.abs(h5py_file['lepton_features/eta'][:]) < 2.4\n",
    "#     cut_delR = np.logical_or(np.logical_and.reduce((h5py_file['lepton_features/pid'][:] == 13, delR[:, 0] > 0.4, delR[:, 1] > 0.4, delR[:, 2] > 0.4, delR[:, 3] > 0.4)),\n",
    "#             np.logical_and.reduce((h5py_file['lepton_features/pid'][:] == 11, delR[:, 0] > 0.3, delR[:, 1] > 0.3, delR[:, 2] > 0.3, delR[:, 3] > 0.3)))\n",
    "#     cut_jet_pt = h5py_file['jet_features/pt'][:, 3] > 30\n",
    "#     cut_jet_eta = np.logical_and.reduce((abs(h5py_file['jet_features/eta'][:, 0]) < 2.4, abs(h5py_file['jet_features/eta'][:, 1]) < 2.4,\n",
    "#                                         abs(h5py_file['jet_features/eta'][:, 2]) < 2.4, abs(h5py_file['jet_features/eta'][:, 3]) < 2.4))\n",
    "#     cut_first4_btag = np.sum(h5py_file['jet_features/btag'][:, :4], axis=1) == 2\n",
    "#     cuts_CMS = np.logical_and.reduce((cut_lepton_pt, cut_lepton_eta, cut_delR, cut_jet_pt, cut_jet_eta, cut_first4_btag))\n",
    "#     cuts = np.logical_and.reduce((cut_reco_top, cut_lepton_pt, cut_lepton_eta, cut_delR, cut_jet_pt, cut_jet_eta, cut_first4_btag))\n",
    "    cuts = np.logical_and(dic['reconstructed_top_mass'] > bins_min, dic['reconstructed_top_mass'] < bins_max)\n",
    "\n",
    "    # Check the state of the event.\n",
    "    state = [1]*len(h5py_file['target/right_target/q1'][:])\n",
    "\n",
    "    # Two permutations for q1 and q2.\n",
    "    permu1 = np.logical_and(h5py_file['target/right_target/q1'][:] == h5py_file[target + '/right_target/q1'][:], \n",
    "                        h5py_file['target/right_target/q2'][:] == h5py_file[target + '/right_target/q2'][:])\n",
    "    permu2 = np.logical_and(h5py_file['target/right_target/q1'][:] == h5py_file[target + '/right_target/q2'][:], \n",
    "                        h5py_file['target/right_target/q2'][:] == h5py_file[target + '/right_target/q1'][:])\n",
    "    correct = np.logical_and(np.logical_or(permu1, permu2), h5py_file['target/right_target/b'][:] == h5py_file[target + '/right_target/b'][:])\n",
    "    state = np.where(correct, 2, state)\n",
    "\n",
    "    # Check for unmatch\n",
    "    unmatch = np.logical_or.reduce((h5py_file['target/right_target/q1'][:] == -1,\n",
    "                        h5py_file['target/right_target/q2'][:] == -1,\n",
    "                        h5py_file['target/right_target/b'][:] == -1))\n",
    "    state = np.where(unmatch, 0, state)\n",
    "    if target == 'klfitter': return dic['reconstructed_top_mass'], state, cuts, h5py_file['klfitter/score/loglikelihood'][:]\n",
    "    elif target == 'spanet': return dic['reconstructed_top_mass'], state, cuts, h5py_file['spanet/right_target/marginal_probability'][:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reco_top_mss from ttbar_testing_mass_variation\n",
    "# 0 for unmatched, 1 for incorrect, 2 for correct\n",
    "\n",
    "reco_klf_dic, state_klf_dic, cut_klf_dic, loglikeli_klf_dic = {}, {}, {}, {}\n",
    "reco_spanet_dic, state_spanet_dic, cut_spanet_dic, marginal_spanet_dic = {}, {}, {}, {}\n",
    "reco_klfm_dic, state_klfm_dic, cut_klfm_dic, loglikeli_klfm_dic = {}, {}, {}, {}\n",
    "\n",
    "for m in mass:\n",
    "    h5py_file = h5py.File('ttbar_testing_mass_variation/ttbar_testing_{}_gev_with_spanet_pdnn_KLFitter.h5'.format(m), \"r\")\n",
    "    reco_spanet_dic[m], state_spanet_dic[m], cut_spanet_dic[m], marginal_spanet_dic[m] = get_reco_top_mass(h5py_file, 'spanet')\n",
    "    reco_klf_dic[m], state_klf_dic[m], cut_klf_dic[m], loglikeli_klf_dic[m]  = get_reco_top_mass(h5py_file, 'klfitter')\n",
    "    h5py_file = h5py.File('h5files_w_klfitter/ttbar_testing_{}_gev_with_spanet_KLFitter.h5'.format(173), \"r\")\n",
    "    reco_klfm_dic[m], state_klfm_dic[m], cut_klfm_dic[m], loglikeli_klfm_dic[m] = get_reco_top_mass(h5py_file, 'klfitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m class_2_ratio \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     class_0_counts_resampled \u001b[38;5;241m=\u001b[39m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_0_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     class_1_counts_resampled \u001b[38;5;241m=\u001b[39m resample(class_1_counts)\n\u001b[1;32m     16\u001b[0m     class_2_counts_resampled \u001b[38;5;241m=\u001b[39m resample(class_2_counts)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/__init__.py:559\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(replace, n_samples, random_state, stratify, *arrays)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    558\u001b[0m first \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 559\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m first\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(first, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_n_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     max_n_samples \u001b[38;5;241m=\u001b[39m n_samples\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "class_0_counts = np.count_nonzero(state_klf_dic[m][np.logical_and(cut_klf_dic[m], loglikeli_klf_dic[m])]==0)\n",
    "class_1_counts = np.count_nonzero(state_klf_dic[m][np.logical_and(cut_klf_dic[m], loglikeli_klf_dic[m])]==1)\n",
    "class_2_counts = np.count_nonzero(state_klf_dic[m][np.logical_and(cut_klf_dic[m], loglikeli_klf_dic[m])]==2)\n",
    "\n",
    "# assume you have three classes, class 0, class 1, and class 2, and you have their counts in three arrays, class_0_counts, class_1_counts, and class_2_counts\n",
    "class_0_ratio = []\n",
    "class_1_ratio = []\n",
    "class_2_ratio = []\n",
    "\n",
    "for i in range(1000):\n",
    "    class_0_counts_resampled = resample(class_0_counts)\n",
    "    class_1_counts_resampled = resample(class_1_counts)\n",
    "    class_2_counts_resampled = resample(class_2_counts)\n",
    "\n",
    "    total_counts_resampled = class_0_counts_resampled + class_1_counts_resampled + class_2_counts_resampled\n",
    "\n",
    "    class_0_ratio_resampled = np.sum(class_0_counts_resampled) / np.sum(total_counts_resampled)\n",
    "    class_1_ratio_resampled = np.sum(class_1_counts_resampled) / np.sum(total_counts_resampled)\n",
    "    class_2_ratio_resampled = np.sum(class_2_counts_resampled) / np.sum(total_counts_resampled)\n",
    "\n",
    "    class_0_ratio.append(class_0_ratio_resampled)\n",
    "    class_1_ratio.append(class_1_ratio_resampled)\n",
    "    class_2_ratio.append(class_2_ratio_resampled)\n",
    "\n",
    "class_0_ratio_mean = np.mean(class_0_ratio)\n",
    "class_1_ratio_mean = np.mean(class_1_ratio)\n",
    "class_2_ratio_mean = np.mean(class_2_ratio)\n",
    "class_0_ratio_std = np.std(class_0_ratio)\n",
    "class_1_ratio_std = np.std(class_1_ratio)\n",
    "class_2_ratio_std = np.std(class_2_ratio)\n",
    "\n",
    "print(\"Class 0 ratio: mean = {}, std = {}\".format(class_0_ratio_mean, class_0_ratio_std))\n",
    "print(\"Class 1 ratio: mean = {}, std = {}\".format(class_1_ratio_mean, class_1_ratio_std))\n",
    "print(\"Class 2 ratio: mean = {}, std = {}\".format(class_2_ratio_mean, class_2_ratio_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 8))\n",
    "m = 173\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "cuts = np.linspace(-110, max(loglikeli_klfm_dic[m]), 100)\n",
    "width = cuts[1] - cuts[0]\n",
    "h_klfm = [0]*(len(cuts)-1)\n",
    "for state_i in [2, 1, 0]:\n",
    "    hist, _ = np.histogram(loglikeli_klfm_dic[m][state_klfm_dic[m]==state_i], bins=cuts)\n",
    "    plt.bar(cuts[:-1]+width/2, hist, bottom=h_klfm, edgecolor=colors[state_i], width=width, color='None', label = state_labels[state_i] + ' histogram')\n",
    "    h_klfm += hist\n",
    "plt.title('klfitter mfixed')\n",
    "plt.xlabel('klf loglikeli')\n",
    "plt.ylabel('event/{:.1f} loglikeli'.format(width))\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "cuts = np.linspace(-110, max(loglikeli_klf_dic[m]), 100)\n",
    "width = cuts[1] - cuts[0]\n",
    "h_klf = [0]*(len(cuts)-1)\n",
    "for state_i in [2, 1, 0]:\n",
    "    hist, _ = np.histogram(loglikeli_klf_dic[m][state_klf_dic[m]==state_i], bins=cuts)\n",
    "    plt.bar(cuts[:-1]+width/2, hist, bottom=h_klf, edgecolor=colors[state_i], width=width, color='None', label = state_labels[state_i] + ' histogram')\n",
    "    h_klf += hist\n",
    "plt.title('klfitter')\n",
    "plt.xlabel('klf loglikeli')\n",
    "plt.ylabel('event/{:.1f} loglikeli'.format(width))\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "cuts = np.linspace(0.01, 0.99, 100)\n",
    "width = cuts[1] - cuts[0]\n",
    "h_spanet = [0]*(len(cuts)-1)\n",
    "for state_i in [2, 1, 0]:\n",
    "    hist, _ = np.histogram(marginal_spanet_dic[m][state_spanet_dic[m]==state_i], bins=cuts)\n",
    "    plt.bar(cuts[:-1]+width/2, hist, bottom=h_spanet, edgecolor=colors[state_i], width=width, color='None', label = state_labels[state_i] + ' histogram')\n",
    "    h_spanet += hist\n",
    "plt.title('spanet')\n",
    "plt.xlabel('spanet marginal prob')\n",
    "plt.ylabel('event/{:.2f} marginal prob'.format(width))\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 8))\n",
    "m = 173\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "cuts = np.linspace(-110, max(loglikeli_klfm_dic[m]), 100)\n",
    "width = cuts[1] - cuts[0]\n",
    "h_klfm_density = [0]*(len(cuts)-1)\n",
    "for state_i in [2, 1, 0]:\n",
    "    hist, _ = np.histogram(loglikeli_klfm_dic[m][state_klfm_dic[m]==state_i], bins=cuts)\n",
    "    plt.bar(cuts[:-1]+width/2, hist/h_klfm, bottom=h_klfm_density, edgecolor=colors[state_i], width=width, color='None', label = state_labels[state_i] + ' histogram')\n",
    "    h_klfm_density += hist/h_klfm\n",
    "plt.title('klfitter mfixed')\n",
    "plt.xlabel('klf loglikeli')\n",
    "plt.ylabel('bin to bin event ratio/{:.1f} loglikeli'.format(width))\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "cuts = np.linspace(-110, max(loglikeli_klf_dic[m]), 100)\n",
    "width = cuts[1] - cuts[0]\n",
    "h_klf_density = [0]*(len(cuts)-1)\n",
    "for state_i in [2, 1, 0]:\n",
    "    hist, _ = np.histogram(loglikeli_klf_dic[m][state_klf_dic[m]==state_i], bins=cuts)\n",
    "    plt.bar(cuts[:-1]+width/2, hist/h_klf, bottom=h_klf_density, edgecolor=colors[state_i], width=width, color='None', label = state_labels[state_i] + ' histogram')\n",
    "    h_klf_density += hist/h_klf\n",
    "plt.title('klfitter')\n",
    "plt.xlabel('klf loglikeli')\n",
    "plt.ylabel('bin to bin event ratio/{:.1f} loglikeli'.format(width))\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "cuts = np.linspace(0.01, 0.99, 100)\n",
    "width = cuts[1] - cuts[0]\n",
    "h_spanet_density = [0]*(len(cuts)-1)\n",
    "for state_i in [2, 1, 0]:\n",
    "    hist, _ = np.histogram(marginal_spanet_dic[m][state_spanet_dic[m]==state_i], bins=cuts)\n",
    "    plt.bar(cuts[:-1]+width/2, hist/h_spanet, bottom=h_spanet_density, edgecolor=colors[state_i], width=width, color='None', label = state_labels[state_i] + ' histogram')\n",
    "    h_spanet_density += hist/h_spanet\n",
    "plt.title('spanet')\n",
    "plt.xlabel('spanet marginal prob')\n",
    "plt.ylabel('bin to bin event ratio/{:.2f} marginal prob'.format(width))\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 8))\n",
    "m = 173\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "tot = []\n",
    "unmatched = []\n",
    "incorrect = []\n",
    "correct = []\n",
    "cuts = np.linspace(-110, max(loglikeli_klfm_dic[m])-1, 100)\n",
    "for cut in cuts:\n",
    "    tot.append(len(reco_klfm_dic[m][loglikeli_klfm_dic[m]>cut]))\n",
    "    unmatched.append(len(reco_klfm_dic[m][np.logical_and.reduce((state_klfm_dic[m] == 0, loglikeli_klfm_dic[m]>cut))]))\n",
    "    incorrect.append(len(reco_klfm_dic[m][np.logical_and.reduce((state_klfm_dic[m] == 1, loglikeli_klfm_dic[m]>cut))]))\n",
    "    correct.append(len(reco_klfm_dic[m][np.logical_and.reduce((state_klfm_dic[m] == 2, loglikeli_klfm_dic[m]>cut))]))\n",
    "width = cuts[1] - cuts[0]\n",
    "tot, unmatched, incorrect, correct = np.array(tot), np.array(unmatched), np.array(incorrect), np.array(correct)\n",
    "h = [0]*len(tot)\n",
    "plt.bar(cuts, correct/tot, bottom=h, edgecolor=colors[2], width=width, color='None', label = state_labels[2] + ' ratio')\n",
    "h += correct/tot\n",
    "plt.bar(cuts, incorrect/tot, bottom=h, edgecolor=colors[1], width=width, color='None', label = state_labels[1] + ' ratio')\n",
    "h += incorrect/tot\n",
    "plt.bar(cuts, unmatched/tot, bottom=h, edgecolor=colors[0], width=width, color='None', label = state_labels[0] + ' ratio')\n",
    "plt.title('klfitter mfixed')\n",
    "plt.xlabel('klf loglikeli')\n",
    "plt.ylabel('ratio')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "tot = []\n",
    "unmatched = []\n",
    "incorrect = []\n",
    "correct = []\n",
    "cuts = np.linspace(-110, max(loglikeli_klf_dic[m])-1, 100)\n",
    "for cut in cuts:\n",
    "    tot.append(len(reco_klf_dic[m][loglikeli_klf_dic[m]>cut]))\n",
    "    unmatched.append(len(reco_klf_dic[m][np.logical_and.reduce((state_klf_dic[m] == 0, loglikeli_klf_dic[m]>cut))]))\n",
    "    incorrect.append(len(reco_klf_dic[m][np.logical_and.reduce((state_klf_dic[m] == 1, loglikeli_klf_dic[m]>cut))]))\n",
    "    correct.append(len(reco_klf_dic[m][np.logical_and.reduce((state_klf_dic[m] == 2, loglikeli_klf_dic[m]>cut))]))\n",
    "\n",
    "width = cuts[1] - cuts[0]\n",
    "tot, unmatched, incorrect, correct = np.array(tot), np.array(unmatched), np.array(incorrect), np.array(correct)\n",
    "h = [0]*len(tot)\n",
    "plt.bar(cuts, correct/tot, bottom=h, edgecolor=colors[2], width=width, color='None', label = state_labels[2] + ' ratio')\n",
    "h += correct/tot\n",
    "plt.bar(cuts, incorrect/tot, bottom=h, edgecolor=colors[1], width=width, color='None', label = state_labels[1] + ' ratio')\n",
    "h += incorrect/tot\n",
    "plt.bar(cuts, unmatched/tot, bottom=h, edgecolor=colors[0], width=width, color='None', label = state_labels[0] + ' ratio')\n",
    "plt.title('klfitter')\n",
    "plt.xlabel('klf loglikeli')\n",
    "plt.ylabel('ratio')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "tot = []\n",
    "unmatched = []\n",
    "incorrect = []\n",
    "correct = []\n",
    "\n",
    "cuts = np.linspace(0.01, 0.99, 100)\n",
    "for cut in cuts:\n",
    "    tot.append(len(reco_spanet_dic[m][marginal_spanet_dic[m]>cut]))\n",
    "    unmatched.append(len(reco_spanet_dic[m][np.logical_and.reduce((state_spanet_dic[m] == 0, marginal_spanet_dic[m]>cut))]))\n",
    "    incorrect.append(len(reco_spanet_dic[m][np.logical_and.reduce((state_spanet_dic[m] == 1, marginal_spanet_dic[m]>cut))]))\n",
    "    correct.append(len(reco_spanet_dic[m][np.logical_and.reduce((state_spanet_dic[m] == 2, marginal_spanet_dic[m]>cut))]))\n",
    "\n",
    "width = cuts[1] - cuts[0]\n",
    "tot, unmatched, incorrect, correct = np.array(tot), np.array(unmatched), np.array(incorrect), np.array(correct)\n",
    "h = [0]*len(tot)\n",
    "plt.bar(cuts, correct/tot, bottom=h, edgecolor=colors[2], width=width, color='None', label = state_labels[2] + ' ratio')\n",
    "h += correct/tot\n",
    "plt.bar(cuts, incorrect/tot, bottom=h, edgecolor=colors[1], width=width, color='None', label = state_labels[1] + ' ratio')\n",
    "h += incorrect/tot\n",
    "plt.bar(cuts, unmatched/tot, bottom=h, edgecolor=colors[0], width=width, color='None', label = state_labels[0] + ' ratio')\n",
    "plt.title('spanet')\n",
    "plt.xlabel('spanet marginal prob')\n",
    "plt.ylabel('ratio')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "eps1_klf = []\n",
    "eps2_klf = []\n",
    "\n",
    "eps1_klfm = []\n",
    "eps2_klfm = []\n",
    "\n",
    "eps1_spanet = []\n",
    "eps2_spanet = []\n",
    "\n",
    "m = 173\n",
    "tot1 = np.count_nonzero(state_klf_dic[m]!=2)\n",
    "tot2 = np.count_nonzero(state_klf_dic[m]==2)\n",
    "for cut in np.linspace(-90, -40, 1000):\n",
    "    eps1_klf.append(1-len(state_klf_dic[m][np.logical_and.reduce((state_klf_dic[m]!=2, loglikeli_klf_dic[m]>cut))])/tot1)\n",
    "    eps2_klf.append(len(state_klf_dic[m][np.logical_and.reduce((state_klf_dic[m]==2, loglikeli_klf_dic[m]>cut))])/tot2)\n",
    "\n",
    "cut = -78    \n",
    "point1 = 1-len(state_klf_dic[m][np.logical_and.reduce((state_klf_dic[m]!=2, loglikeli_klf_dic[m]>cut))])/tot1\n",
    "point2 = len(state_klf_dic[m][np.logical_and.reduce((state_klf_dic[m]==2, loglikeli_klf_dic[m]>cut))])/tot2\n",
    "print('klfiter')\n",
    "print('epsilon_cp = {:.4f}, 1-epsilon_wp, un = {:.4f}'.format(point2, point1))\n",
    "print('cp = {:.4f}, wp = {:.4f}, un = {:.4f}'.format(\n",
    "    np.count_nonzero(np.logical_and.reduce((state_klf_dic[m]==2, loglikeli_klf_dic[m]>cut)))/np.count_nonzero(loglikeli_klf_dic[m]>cut),\n",
    "    np.count_nonzero(np.logical_and.reduce((state_klf_dic[m]==1, loglikeli_klf_dic[m]>cut)))/np.count_nonzero(loglikeli_klf_dic[m]>cut),\n",
    "    np.count_nonzero(np.logical_and.reduce((state_klf_dic[m]==0, loglikeli_klf_dic[m]>cut)))/np.count_nonzero(loglikeli_klf_dic[m]>cut)))\n",
    "plt.scatter(point1, point2, label='klf loglike > -78')\n",
    "\n",
    "tot1 = np.count_nonzero(state_klfm_dic[m]!=2)\n",
    "tot2 = np.count_nonzero(state_klfm_dic[m]==2)\n",
    "for cut in np.linspace(-90, -30, 1000):\n",
    "    eps1_klfm.append(1-len(state_klfm_dic[m][np.logical_and.reduce((state_klfm_dic[m]!=2, loglikeli_klfm_dic[m]>cut))])/tot1)\n",
    "    eps2_klfm.append(len(state_klfm_dic[m][np.logical_and.reduce((state_klfm_dic[m]==2, loglikeli_klfm_dic[m]>cut))])/tot2)\n",
    "\n",
    "cut = -75\n",
    "point1 = 1-len(state_klfm_dic[m][np.logical_and.reduce((state_klfm_dic[m]!=2, loglikeli_klfm_dic[m]>cut))])/tot1\n",
    "point2 = len(state_klfm_dic[m][np.logical_and.reduce((state_klfm_dic[m]==2, loglikeli_klfm_dic[m]>cut))])/tot2\n",
    "print('klfiter mfixed')\n",
    "print('epsilon_cp = {:.4f}, 1-epsilon_wp, un = {:.4f}'.format(point2, point1))\n",
    "print('cp = {:.4f}, wp = {:.4f}, un = {:.4f}'.format(\n",
    "    np.count_nonzero(np.logical_and.reduce((state_klfm_dic[m]==2, loglikeli_klfm_dic[m]>cut)))/np.count_nonzero(loglikeli_klfm_dic[m]>cut),\n",
    "    np.count_nonzero(np.logical_and.reduce((state_klfm_dic[m]==1, loglikeli_klfm_dic[m]>cut)))/np.count_nonzero(loglikeli_klfm_dic[m]>cut),\n",
    "    np.count_nonzero(np.logical_and.reduce((state_klfm_dic[m]==0, loglikeli_klfm_dic[m]>cut)))/np.count_nonzero(loglikeli_klfm_dic[m]>cut)))\n",
    "plt.scatter(point1, point2, label='klf (mfixed) loglike > -75')\n",
    "\n",
    "tot1 = np.count_nonzero(state_spanet_dic[m]!=2)\n",
    "tot2 = np.count_nonzero(state_spanet_dic[m]==2)\n",
    "for cut in np.linspace(0.001, 0.99, 1000):\n",
    "    eps1_spanet.append(1-len(state_spanet_dic[m][np.logical_and.reduce((state_spanet_dic[m]!=2, marginal_spanet_dic[m]>cut))])/tot1)\n",
    "    eps2_spanet.append(len(state_spanet_dic[m][np.logical_and.reduce((state_spanet_dic[m]==2, marginal_spanet_dic[m]>cut))])/tot2)\n",
    "\n",
    "cut = 0.23\n",
    "point1 = 1-len(state_spanet_dic[m][np.logical_and.reduce((state_spanet_dic[m]!=2, marginal_spanet_dic[m]>cut))])/tot1\n",
    "point2 = len(state_spanet_dic[m][np.logical_and.reduce((state_spanet_dic[m]==2, marginal_spanet_dic[m]>cut))])/tot2\n",
    "plt.scatter(point1, point2, label='spanet marginal prob > 0.23')\n",
    "print('spanet')\n",
    "print('epsilon_cp = {:.4f}, 1-epsilon_wp, un = {:.4f}'.format(point2, point1))\n",
    "print('cp = {:.4f}, wp = {:.4f}, un = {:.4f}'.format(\n",
    "    np.count_nonzero(np.logical_and.reduce((state_spanet_dic[m]==2, marginal_spanet_dic[m]>cut)))/np.count_nonzero(marginal_spanet_dic[m]>cut),\n",
    "    np.count_nonzero(np.logical_and.reduce((state_spanet_dic[m]==1, marginal_spanet_dic[m]>cut)))/np.count_nonzero(marginal_spanet_dic[m]>cut),\n",
    "    np.count_nonzero(np.logical_and.reduce((state_spanet_dic[m]==0, marginal_spanet_dic[m]>cut)))/np.count_nonzero(marginal_spanet_dic[m]>cut)))\n",
    "\n",
    "plt.plot(eps1_klf, eps2_klf, label = 'KLFitter marginal cut')\n",
    "plt.plot(eps1_klfm, eps2_klfm, label = 'KLFitter (mfixed) marginal cut')\n",
    "plt.plot(eps1_spanet, eps2_spanet, label = 'SPAnet loglikelihood cut')\n",
    "plt.xlabel(r'1 - $\\epsilon_{wp+un}$')\n",
    "plt.ylabel(r'$\\epsilon_{cp}$')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglikeli_total_event = defaultdict(list)\n",
    "loglikeli_correct_number = defaultdict(list)\n",
    "\n",
    "marginal_total_event = defaultdict(list)\n",
    "marginal_correct_number = defaultdict(list)\n",
    "\n",
    "m = 173\n",
    "for cut in np.linspace(-80, -60, 100):\n",
    "    loglikeli_total_event[m].append(len(state_klf_dic[m][np.logical_and(cut_klf_dic[m], loglikeli_klf_dic[m]>cut)]))\n",
    "    loglikeli_correct_number[m].append(np.count_nonzero(state_klf_dic[m][np.logical_and(cut_klf_dic[m], loglikeli_klf_dic[m]>cut)] != 0))\n",
    "\n",
    "for cut2 in np.linspace(0.1, 0.9, 100):\n",
    "    marginal_total_event[m].append(len(state_spanet_dic[m][np.logical_and(cut_spanet_dic[m], marginal_spanet_dic[m]>cut2)]))\n",
    "    marginal_correct_number[m].append(np.count_nonzero(state_spanet_dic[m][np.logical_and(cut_spanet_dic[m], marginal_spanet_dic[m]>cut2)] != 0))\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loglikeli_total_event[m], loglikeli_correct_number[m], label = 'KLFitter marginal cut')\n",
    "plt.plot(marginal_total_event[m], marginal_correct_number[m], label = 'SPAnet loglikelihood cut')\n",
    "plt.xlabel('Total event')\n",
    "plt.ylabel('Correct number')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim(20000, 180000)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loglikeli_total_event[m], np.array(loglikeli_correct_number[m])/loglikeli_total_event[m], label = 'KLFitter marginal cut')\n",
    "plt.plot(marginal_total_event[m], np.array(marginal_correct_number[m])/marginal_total_event[m], label = 'SPAnet loglikelihood cut')\n",
    "plt.xlabel('Total event')\n",
    "plt.ylabel('Correct ratio')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(20000, 180000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "JSF = 1\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(reco_klf_dic[JSF], bins=bins, histtype='step', label='klf')\n",
    "plt.hist(reco_spanet_dic[JSF], bins=bins, histtype='step', label='spanet')\n",
    "plt.xlabel('reco top mass (GeV)')\n",
    "plt.ylabel('event/GeV')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(reco_klf_dic[JSF][np.logical_and.reduce((cut_klf_dic[JSF], loglikeli_klf_dic[JSF]>loglikeli_cut))], bins=bins,  histtype='step', label='klf')\n",
    "plt.hist(reco_spanet_dic[JSF][np.logical_and.reduce((cut_spanet_dic[JSF], marginal_spanet_dic[JSF]>marginal_prob_cut))], bins=bins,  histtype='step', label='spanet')\n",
    "plt.xlabel('reco top mass (GeV)')\n",
    "plt.ylabel('event/GeV')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.xlabel('reco top mass (GeV)')\n",
    "plt.ylabel('event/GeV')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.xlabel('reco top mass (GeV)')\n",
    "plt.ylabel('event/GeV')\n",
    "plt.legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_klf_dic = defaultdict(list)\n",
    "for i, m in enumerate(mass):\n",
    "    for state_i in [0, 1, 2]:\n",
    "        ratio = np.count_nonzero(state_klf_dic[m][np.logical_and(cut_klf_dic[m], loglikeli_klf_dic[m]>loglikeli_cut)]==state_i)/len(state_klf_dic[m][np.logical_and(cut_klf_dic[m], loglikeli_klf_dic[m]>loglikeli_cut)])\n",
    "        ratio_klf_dic[state_i].append(ratio)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "for state_i in [0, 1, 2]:\n",
    "    plt.subplot(1, 3, state_i+1)\n",
    "    plt.scatter(mass, ratio_klf_dic[state_i])\n",
    "    plt.title('KLF ' + state_labels[state_i])\n",
    "    plt.xlabel('top mass (GeV)')\n",
    "    plt.ylabel('ratio')\n",
    "plt.savefig('./plots_topmass/klf_ratio.png')\n",
    "plt.show()\n",
    "ratio_klf = {key:np.mean(ratio_klf_dic[key]) for key in ratio_klf_dic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_spanet_dic = defaultdict(list)\n",
    "for i, m in enumerate(mass):\n",
    "    for state_i in [0, 1, 2]:\n",
    "        ratio = np.count_nonzero(state_spanet_dic[m][np.logical_and(cut_spanet_dic[m], marginal_spanet_dic[m]>marginal_prob_cut)]==state_i)/len(state_spanet_dic[m][np.logical_and(cut_spanet_dic[m], marginal_spanet_dic[m]>marginal_prob_cut)])\n",
    "        ratio_spanet_dic[state_i].append(ratio)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "for state_i in [0, 1, 2]:\n",
    "    plt.subplot(1, 3, state_i+1)\n",
    "    plt.scatter(mass, ratio_spanet_dic[state_i])\n",
    "    plt.title('SPANET ' + state_labels[state_i])\n",
    "    plt.xlabel('top mass (GeV)')\n",
    "    plt.ylabel('ratio')\n",
    "plt.savefig('./plots_topmass/spanet_ratio.png')\n",
    "plt.show()\n",
    "ratio_spanet = {key:np.mean(ratio_spanet_dic[key]) for key in ratio_spanet_dic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of a Landau distribution and a gaussian distribution. Landau currently uses moyal as approximation.\n",
    "# Nomalized\n",
    "def langau(x, lan_loc, lan_scale, gau_loc, gau_scale, f):\n",
    "    lan_y = (x-lan_loc)/lan_scale\n",
    "    gau_y = (x-gau_loc)/gau_scale\n",
    "    return (1-f)*np.exp(-(lan_y+np.exp(-lan_y))/2)/np.sqrt(2*np.pi)/lan_scale + f*np.exp(-gau_y**2/2)/np.sqrt(2*np.pi)/gau_scale\n",
    "\n",
    "# Normalized between bins_min and bins_max\n",
    "def langau_norm(x, lan_loc, lan_scale, gau_loc, gau_scale, f):\n",
    "    return langau(x, lan_loc, lan_scale, gau_loc, gau_scale, f)/integrate.quad(langau, bins_min, bins_max, args=(lan_loc, lan_scale, gau_loc, gau_scale, f))[0]\n",
    "\n",
    "# Two gaussian distributions.\n",
    "# Nomalized\n",
    "def two_gau(x, gau_loc1, gau_scale1, gau_loc2, gau_scale2, f):\n",
    "    gau_y1 = (x-gau_loc1)/gau_scale1\n",
    "    gau_y2 = (x-gau_loc2)/gau_scale2\n",
    "    return (1-f)*np.exp(-gau_y1**2/2)/np.sqrt(2*np.pi)/gau_scale1 + f*np.exp(-gau_y2**2/2)/np.sqrt(2*np.pi)/gau_scale2\n",
    "\n",
    "# Normalized between bins_min and bins_max\n",
    "def two_gau_norm(x, gau_loc1, gau_scale1, gau_loc2, gau_scale2, f):\n",
    "    return two_gau(x, gau_loc1, gau_scale1, gau_loc2, gau_scale2, f)/integrate.quad(two_gau, bins_min, bins_max, args=(gau_loc1, gau_scale1, gau_loc2, gau_scale2, f))[0]\n",
    "\n",
    "# Gaussian distributions.\n",
    "def gau_norm(x, gau_loc1, gau_scale1):\n",
    "    gau_y1 = (x-gau_loc1)/gau_scale1\n",
    "    return np.exp(-gau_y1**2/2)/np.sqrt(2*np.pi)/gau_scale1\n",
    "\n",
    "def voigt(x, shift, sigma, gamma):\n",
    "    return scipy.special.voigt_profile(x - shift, sigma, gamma)\n",
    "\n",
    "def voigt_norm(x, shift, sigma, gamma):\n",
    "    return voigt(x, shift, sigma, gamma)/integrate.quad(voigt, bins_min, bins_max, args=(shift, sigma, gamma))[0]\n",
    "\n",
    "# Linear\n",
    "def linear(x, a, b):\n",
    "    return a*x+b\n",
    "\n",
    "def chi2_pdf(observed, pdf): #observed is the observation, pdf is the normalized height of the bins from pdf.\n",
    "    n1, _ = np.histogram(observed, bins=bins)\n",
    "    n2 = pdf*bins_w*len(observed)\n",
    "    return np.sum((n1-n2)**2/n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit every class of klfitter\n",
    "fita_klf_dic, fitb_klf_dic = {}, {}\n",
    "fit_popt_dic = {}\n",
    "fit_perr_dic = {}\n",
    "\n",
    "for state_i in [0, 1, 2]:\n",
    "    popt_klf_arr = []\n",
    "    perr_klf_arr = []\n",
    "\n",
    "    plt.figure(figsize=(30, 15))\n",
    "    for i, m in enumerate(mass):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        fit_target = reco_klf_dic[m][np.logical_and.reduce((cut_klf_dic[m], state_klf_dic[m] == state_i, loglikeli_klf_dic[m]>loglikeli_cut))]\n",
    "        hist, _ = np.histogram(fit_target, bins=bins, density=True)\n",
    "        sigma = np.sqrt(np.histogram(fit_target, bins=bins)[0])/len(fit_target)\n",
    "        \n",
    "        # 2Gaussian for correct\n",
    "        if state_i == 2:\n",
    "            popt, pcov = optimize.curve_fit(two_gau_norm, bins_mid, hist, sigma=sigma, p0=(180, 10, 170, 25, 0.9), bounds=((120, 5, 140, 18, 0), (200, 18, 200, 35, 1)))\n",
    "            y_dense = two_gau_norm(bins_dense, *popt)\n",
    "            chi2 = chi2_pdf(fit_target, two_gau_norm(bins_mid, *popt))\n",
    "\n",
    "        # Landau + Gaussian for incorrect and unmatch\n",
    "        else:\n",
    "            popt, pcov = optimize.curve_fit(langau_norm, bins_mid, hist, sigma=sigma, p0=(150, 20, 160, 20, 0.9), bounds=((120, 10, 120, 10, 0), (220, 50, 220, 30, 1)))\n",
    "            y_dense = langau_norm(bins_dense, *popt)\n",
    "            chi2 = chi2_pdf(fit_target, langau_norm(bins_mid, *popt))\n",
    "\n",
    "        popt_klf_arr.append(popt)\n",
    "        perr_klf_arr.append(np.sqrt(np.diag(pcov)))\n",
    "        plt.bar(bins[:-1]+1, hist, edgecolor=colors[state_i], width=bins_w, color='None', label = state_labels[state_i] + ' histogram')\n",
    "        plt.plot(bins_dense, y_dense, c='r', label='binned chi2 = {:.2f}'.format(chi2))\n",
    "        plt.title('klf {}, loglikelihood > {}'.format(state_labels[state_i], loglikeli_cut))\n",
    "        plt.xlabel('reco top mass (GeV)')\n",
    "        plt.ylabel('event/GeV')\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    popt_klf_arr = np.transpose(np.array(popt_klf_arr))\n",
    "    fit_popt_dic[state_i] = popt_klf_arr\n",
    "    perr_klf_arr = np.transpose(np.array(perr_klf_arr))\n",
    "    fita_klf_arr, fitb_klf_arr = [], []\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i, arr in enumerate(popt_klf_arr):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        popt, pcov = optimize.curve_fit(linear, mass, arr, sigma=perr_klf_arr[i], method=\"lm\")\n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "        plt.errorbar(mass, arr, yerr = perr_klf_arr[i], fmt='o', elinewidth=bins_w, capsize=4, label='binned parameters')\n",
    "        y = linear(top_mass_dense, popt[0], popt[1])\n",
    "        plt.plot(top_mass_dense, y, label='binned linear fit')\n",
    "        plt.xlabel('True top mass (GeV)')\n",
    "        if state_i == 2: plt.ylabel(two_gau_fit_labels[i])\n",
    "        else: plt.ylabel(langau_fit_labels[i])\n",
    "        plt.title('klf parameters fit')\n",
    "        fita_klf_arr.append(popt[0])\n",
    "        fitb_klf_arr.append(popt[1])\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    fita_klf_dic[state_i] = fita_klf_arr\n",
    "    fitb_klf_dic[state_i] = fitb_klf_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit every class of spanet\n",
    "fita_spanet_dic, fitb_spanet_dic = {}, {}\n",
    "fit_popt_dic = {}\n",
    "fit_perr_dic = {}\n",
    "\n",
    "for state_i in [0, 1, 2]:\n",
    "    popt_spanet_arr = []\n",
    "    perr_spanet_arr = []\n",
    "    \n",
    "    plt.figure(figsize=(30, 15))\n",
    "    for i, m in enumerate(mass):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        fit_target = reco_spanet_dic[m][np.logical_and.reduce((cut_spanet_dic[m], state_spanet_dic[m] == state_i, marginal_spanet_dic[m]>marginal_prob_cut))]\n",
    "        hist, _ = np.histogram(fit_target, bins=bins, density=True)\n",
    "        sigma = np.sqrt(np.histogram(fit_target, bins=bins)[0])/len(fit_target)\n",
    "        \n",
    "        # 2Gaussian for correct\n",
    "        if state_i == 2:\n",
    "            popt, pcov = optimize.curve_fit(two_gau_norm, bins_mid, hist, sigma=sigma, p0=(180, 10, 170, 25, 0.9), bounds=((120, 5, 140, 18, 0), (200, 18, 200, 35, 1)))\n",
    "            y_dense = two_gau_norm(bins_dense, *popt)\n",
    "            chi2 = chi2_pdf(fit_target, two_gau_norm(bins_mid, *popt))\n",
    "\n",
    "        # Landau + Gaussian for incorrect and unmatch\n",
    "        else:\n",
    "            popt, pcov = optimize.curve_fit(langau_norm, bins_mid, hist, sigma=sigma, p0=(150, 20, 160, 20, 0.9), bounds=((120, 10, 120, 10, 0), (220, 50, 220, 30, 1)))\n",
    "            y_dense = langau_norm(bins_dense, *popt)\n",
    "            chi2 = chi2_pdf(fit_target, langau_norm(bins_mid, *popt))\n",
    "\n",
    "        popt_spanet_arr.append(popt)\n",
    "        perr_spanet_arr.append(np.sqrt(np.diag(pcov)))\n",
    "        plt.bar(bins[:-1]+1, hist, edgecolor=colors[state_i], width=bins_w, color='None', label = state_labels[state_i] + ' histogram')\n",
    "        plt.plot(bins_dense, y_dense, c='r', label='binned chi2 = {:.2f}'.format(chi2))\n",
    "        plt.title('spanet {}, marginal probability > {}'.format(state_labels[state_i], marginal_prob_cut))\n",
    "        plt.xlabel('reco top mass (GeV)')\n",
    "        plt.ylabel('event/GeV')\n",
    "        plt.legend(loc = 'upper right')\n",
    "    plt.show()\n",
    "\n",
    "    popt_spanet_arr = np.transpose(np.array(popt_spanet_arr))\n",
    "    fit_popt_dic[state_i] = popt_spanet_arr\n",
    "    perr_spanet_arr = np.transpose(np.array(perr_spanet_arr))\n",
    "    fita_spanet_arr, fitb_spanet_arr = [], []\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i, arr in enumerate(popt_spanet_arr):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        popt, pcov = optimize.curve_fit(linear, mass, arr, sigma=perr_spanet_arr[i], method=\"lm\")\n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "        plt.errorbar(mass, arr, yerr = perr_spanet_arr[i], fmt='o', elinewidth=bins_w, capsize=4, label='binned parameters')\n",
    "        y = linear(top_mass_dense, popt[0], popt[1])\n",
    "        plt.plot(top_mass_dense, y, label='binned linear fit')\n",
    "        plt.xlabel('True top mass (GeV)')\n",
    "        if state_i == 2: plt.ylabel(two_gau_fit_labels[i])\n",
    "        else: plt.ylabel(langau_fit_labels[i])\n",
    "        plt.title('spanet {}, marginal probability > 0.3'.format(state_labels[state_i]))\n",
    "        fita_spanet_arr.append(popt[0])\n",
    "        fitb_spanet_arr.append(popt[1])\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    fita_spanet_dic[state_i] = fita_spanet_arr\n",
    "    fitb_spanet_dic[state_i] = fitb_spanet_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state_i in [0, 1, 2]:\n",
    "    plt.figure(figsize=(30,15))\n",
    "    for i, m in enumerate([172, 173, 173]):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        target = reco_klf_dic[m][np.logical_and.reduce((cut_klf_dic[m], state_klf_dic[m] == state_i, loglikeli_klf_dic[m]>loglikeli_cut))]\n",
    "        hist, bin_edges = np.histogram(target, bins=bins, density=True)\n",
    "        popt = np.array(fita_klf_dic[state_i])*m+fitb_klf_dic[state_i]\n",
    "        if state_i  == 2:\n",
    "            y_template_dense_norm = two_gau_norm(bins_dense, *popt)\n",
    "            chi2_pdf_value = chi2_pdf(target, two_gau_norm(bins_mid, *popt))\n",
    "        else:\n",
    "            y_template_dense_norm = langau_norm(bins_dense, *popt)\n",
    "            chi2_pdf_value = chi2_pdf(target, langau_norm(bins_mid, *popt))\n",
    "\n",
    "        plt.bar(bin_edges[:-1]+1, hist, edgecolor=colors[state_i], width=bins_w, color='None', label = state_labels[state_i] + ' histogram')\n",
    "        plt.plot(bins_dense, y_template_dense_norm, c='r', label='PDF, chi2 = {:.2f}'.format(chi2_pdf_value))\n",
    "        plt.title('KLFitter {}, top mass = {}'.format(state_labels[state_i], m))\n",
    "        plt.xlabel('reco top mass (GeV)')\n",
    "        plt.ylabel('density')\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state_i in [0, 1, 2]:\n",
    "    plt.figure(figsize=(30,15))\n",
    "    for i, m in enumerate([172, 173, 174]):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        target = reco_spanet_dic[m][np.logical_and.reduce((cut_spanet_dic[m], state_spanet_dic[m] == state_i, marginal_spanet_dic[m]>marginal_prob_cut))]\n",
    "        hist, bin_edges = np.histogram(target, bins=bins, density=True)\n",
    "        popt = np.array(fita_spanet_dic[state_i])*m+fitb_spanet_dic[state_i]\n",
    "        if state_i  == 2:\n",
    "            y_template_dense_norm = two_gau_norm(bins_dense, *popt)\n",
    "            chi2_pdf_value = chi2_pdf(target, two_gau_norm(bins_mid, *popt))\n",
    "        else:\n",
    "            y_template_dense_norm = langau_norm(bins_dense, *popt)\n",
    "            chi2_pdf_value = chi2_pdf(target, langau_norm(bins_mid, *popt))\n",
    "\n",
    "        plt.bar(bin_edges[:-1]+1, hist, edgecolor=colors[state_i], width=bins_w, color='None', label = state_labels[state_i] + ' histogram')\n",
    "        plt.plot(bins_dense, y_template_dense_norm, c='r', label='PDF, chi2 = {:.2f}'.format(chi2_pdf_value))\n",
    "        plt.title('SPANET {}, top mass = {}'.format(state_labels[state_i], m))\n",
    "        plt.xlabel('reco top mass (GeV)')\n",
    "        plt.ylabel('density')\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_klf_pdf_func(x, m):\n",
    "    hist = [0]*len(x)\n",
    "    for state_i in [0, 1, 2]:\n",
    "        popt = np.array(fita_klf_dic[state_i])*m + fitb_klf_dic[state_i]\n",
    "        if state_i == 2: hist += two_gau_norm(x, *popt)*ratio_klf[state_i]\n",
    "        else: hist += langau_norm(x, *popt)*ratio_klf[state_i]\n",
    "    return hist\n",
    "\n",
    "def combine_spanet_pdf_func(x, m):\n",
    "    hist = [0]*len(x)\n",
    "    for state_i in [0, 1, 2]:\n",
    "        popt = np.array(fita_spanet_dic[state_i])*m + fitb_spanet_dic[state_i]\n",
    "        if state_i == 2: hist += two_gau_norm(x, *popt)*ratio_spanet[state_i]\n",
    "        else: hist += langau_norm(x, *popt)*ratio_spanet[state_i]\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "for i, m in enumerate(mass):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    target = reco_klf_dic[m][np.logical_and.reduce((cut_klf_dic[m], loglikeli_klf_dic[m]>loglikeli_cut))]\n",
    "    klf_pdf = combine_klf_pdf_func(bins_dense, m)\n",
    "    chi2_pdf_value = chi2_pdf(target, combine_klf_pdf_func(bins_mid, m))\n",
    "\n",
    "    h, tot = [0]*(len(bins)-1), len(target)\n",
    "    for state_i in [0, 1, 2]:\n",
    "        hist, _ = np.histogram(reco_klf_dic[m][np.logical_and.reduce((state_klf_dic[m] == state_i, cut_klf_dic[m], loglikeli_klf_dic[m]>loglikeli_cut))], bins=bins)\n",
    "        plt.bar(bins_mid, hist/tot/bins_w, bottom=h, edgecolor=colors[state_i], width=bins_w, color='None', label = state_labels[state_i] + ' histogram')\n",
    "        h += hist/tot/bins_w\n",
    "\n",
    "    plt.plot(bins_dense, klf_pdf, c='r', label='Combined pdf, chi2 = {:.2f}'.format(chi2_pdf_value))\n",
    "    plt.title('klfitter, top mass = {}'.format(m))\n",
    "    plt.xlabel('reco top mass (GeV)')\n",
    "    plt.ylabel('density')\n",
    "    plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "for i, m in enumerate(mass):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    target = reco_spanet_dic[m][np.logical_and.reduce((cut_spanet_dic[m], marginal_spanet_dic[m]>marginal_prob_cut))]\n",
    "    spanet_pdf = combine_spanet_pdf_func(bins_dense, m)\n",
    "    chi2_pdf_value = chi2_pdf(target, combine_spanet_pdf_func(bins_mid, m))\n",
    "\n",
    "    h, tot = [0]*(len(bins)-1), len(target)\n",
    "    for state_i in [0, 1, 2]:\n",
    "        hist, _ = np.histogram(reco_spanet_dic[m][np.logical_and.reduce((state_spanet_dic[m] == state_i, cut_spanet_dic[m], marginal_spanet_dic[m]>marginal_prob_cut))], bins=bins)\n",
    "        plt.bar(bins_mid, hist/tot/bins_w, bottom=h, edgecolor=colors[state_i], width=bins_w, color='None', label = state_labels[state_i] + ' histogram')\n",
    "        h += hist/tot/bins_w\n",
    "\n",
    "    plt.plot(bins_dense, spanet_pdf, c='r', label='Combined pdf, chi2 = {:.2f}'.format(chi2_pdf_value))\n",
    "    plt.title('SPANET, top mass = {}'.format(m))\n",
    "    plt.xlabel('reco top mass (GeV)')\n",
    "    plt.ylabel('density')\n",
    "    plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_klf_arr_func(m):\n",
    "    return -2*np.sum(n1*(np.log(combine_klf_pdf_func(bins_mid, m)*len(n1)*bins_w))) + 2*len(n1)\n",
    "\n",
    "def chi2_spanet_arr_func(m):\n",
    "    return -2*np.sum(n1*(np.log(combine_spanet_pdf_func(bins_mid, m)*len(n1)*bins_w))) + 2*len(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 180000\n",
    "m = 173\n",
    "plt.figure(figsize=(10, 6))\n",
    "sudo_klf = reco_klf_dic[m][np.logical_and.reduce((cut_klf_dic[m], loglikeli_klf_dic[m]>loglikeli_cut))][:n]\n",
    "n1 = np.histogram(sudo_klf, bins=bins)[0]\n",
    "# n1 = combine_klf_pdf_func(bins_mid, m)*tot_event*bins_w\n",
    "# n1 = np.random.poisson(n1)\n",
    "\n",
    "minuit = Minuit(chi2_klf_arr_func, m=m)\n",
    "minuit.migrad()\n",
    "minuit.hesse()\n",
    "minuit.minos()\n",
    "a, fa, ok = minuit.mnprofile(\"m\")\n",
    "plt.plot(a, fa-min(fa))\n",
    "plt.scatter(minuit.values['m'], 0, label='klf best fit = {:.3f}({:.3f})'.format(minuit.values['m'], minuit.errors['m']))\n",
    "\n",
    "sudo_spanet = reco_spanet_dic[m][np.logical_and.reduce((cut_spanet_dic[m], marginal_spanet_dic[m]>marginal_prob_cut))][:n]\n",
    "n1 = np.histogram(sudo_spanet, bins=bins)[0]\n",
    "# n1 = combine_spanet_pdf_func(bins_mid, m)*tot_event*bins_w\n",
    "# n1 = np.random.poisson(n1)\n",
    "\n",
    "minuit = Minuit(chi2_spanet_arr_func, m=m)\n",
    "minuit.migrad()\n",
    "minuit.hesse()\n",
    "minuit.minos()\n",
    "a, fa, ok = minuit.mnprofile(\"m\")\n",
    "plt.plot(a, fa-min(fa))\n",
    "plt.scatter(minuit.values['m'], 0, label='spanet best fit = {:.3f}({:.3f})'.format(minuit.values['m'], minuit.errors['m']))\n",
    "\n",
    "plt.axhline(1, c='r')\n",
    "plt.title(r'Template $\\chi^2$, select first 180000')\n",
    "plt.xlabel('top mass (GeV)')\n",
    "plt.ylabel(r'$\\Delta \\chi^2$')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 173\n",
    "sudo_spanet = reco_spanet_dic[m][np.logical_and.reduce((cut_spanet_dic[m], marginal_spanet_dic[m]>marginal_prob_cut))]\n",
    "n1 = np.histogram(sudo_spanet, bins=bins)[0]\n",
    "n1 = combine_spanet_pdf_func(bins_mid, m)*len(sudo_spanet)*bins_w\n",
    "minuit = Minuit(chi2_spanet_arr_func_n, m=m, N=np.sum(n1))\n",
    "minuit.migrad()\n",
    "minuit.hesse()\n",
    "minuit.minos()\n",
    "a, fa, ok = minuit.mnprofile(\"m\")\n",
    "plt.plot(a, fa-min(fa))\n",
    "plt.axhline(1, c='r')\n",
    "plt.scatter(minuit.values['m'], 0, label='best fit = {:.3f}({:.3f})'.format(minuit.values['m'], minuit.errors['m']))\n",
    "plt.title('Without additional cuts')\n",
    "plt.xlabel('top mass (GeV)')\n",
    "plt.ylabel(r'$\\Delta \\chi^2$')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "print(minuit.values['N'])\n",
    "print(minuit.errors['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sudo experiment for KLFitter top mass\n",
    "sudo_klf_top_mean_dic = {}\n",
    "sudo_klf_top_std_dic = {}\n",
    "\n",
    "for m in mass:\n",
    "    sudo_klf = reco_klf_dic[m][np.logical_and.reduce((cut_klf_dic[m], loglikeli_klf_dic[m]>loglikeli_cut))]\n",
    "    n1_arr = np.random.poisson(np.histogram(sudo_klf, bins=bins)[0], size=(sudo_event, (bins_max-bins_min)//bins_w))\n",
    "    mean, std = [], []\n",
    "    for i in range(sudo_event):\n",
    "        n1 = n1_arr[i]\n",
    "        minuit = Minuit(chi2_klf_arr_func_n, m=m, N=np.sum(n1))\n",
    "        minuit.migrad()\n",
    "        minuit.hesse()\n",
    "        minuit.minos()\n",
    "        mean.append(minuit.values['m'])\n",
    "        std.append(minuit.errors['m'])\n",
    "    sudo_klf_top_mean_dic[m] = mean\n",
    "    sudo_klf_top_std_dic[m] = std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 173\n",
    "print(sudo_klf_top_mean_dic[m][0])\n",
    "print(sudo_klf_top_std_dic[m][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(mass, [np.mean(sudo_klf_top_mean_dic[m])-m for m in mass], yerr=[np.std(sudo_klf_top_mean_dic[m])/np.sqrt(sudo_event) for m in mass])\n",
    "plt.title('bias for different top mass')\n",
    "plt.xlabel('top mass (GeV)')\n",
    "plt.ylabel('bias (GeV)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 6))\n",
    "\n",
    "klf_top_bias = np.mean([np.mean(sudo_klf_top_mean_dic[m])-m for m in mass])\n",
    "klf_top_pull = [(np.array(sudo_klf_top_mean_dic[m])-m-klf_top_bias)/sudo_klf_top_std_dic[m] for m in mass]\n",
    "hist, bin_edges = np.histogram(klf_top_pull, bins=np.arange(-10, 10, 0.2), density=True)\n",
    "popt, pcov = optimize.curve_fit(gau_norm, bin_edges[:-1]+0.1, hist)\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "plt.bar(bin_edges[:-1]+0.1, hist, edgecolor='b', width=0.2, color='None', label = 'Mean = {:.4f} ({:.4f}), std = {:.4f} ({:.4f})'.format(popt[0], perr[0], popt[1], perr[1]))\n",
    "plt.title('klfitter top mass pull histogram')\n",
    "plt.xlim(-10, 10)\n",
    "plt.xlabel('top mass pull')\n",
    "plt.ylabel('Number')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sudo experiment for KLFitter top mass\n",
    "sudo_klf_top_pdf_mean_dic = {}\n",
    "sudo_klf_top_pdf_std_dic = {}\n",
    "\n",
    "for m in mass:\n",
    "    sudo_klf = reco_klf_dic[m][np.logical_and.reduce((cut_klf_dic[m], loglikeli_klf_dic[m]>loglikeli_cut))]\n",
    "    sudo_klf_pdf = combine_klf_pdf_func(bins_mid, m)*len(sudo_klf)*bins_w\n",
    "    n1_arr = np.random.poisson(combine_klf_pdf_func(bins_mid, m)*len(sudo_klf)*bins_w, size=(sudo_event, (bins_max-bins_min)//bins_w))\n",
    "    mean, std = [], []\n",
    "    for i in range(sudo_event):\n",
    "        n1 = n1_arr[i]\n",
    "        minuit = Minuit(chi2_klf_arr_func_n, m=m, N=np.sum(n1))\n",
    "        minuit.migrad()\n",
    "        minuit.hesse()\n",
    "        minuit.minos()\n",
    "        mean.append(minuit.values['m'])\n",
    "        std.append(minuit.errors['m'])\n",
    "    sudo_klf_top_pdf_mean_dic[m] = mean\n",
    "    sudo_klf_top_pdf_std_dic[m] = std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 6))\n",
    "\n",
    "klf_top_bias = np.mean([np.mean(sudo_klf_top_pdf_mean_dic[m])-m for m in mass])\n",
    "klf_top_pull = [(np.array(sudo_klf_top_pdf_mean_dic[m])-m-klf_top_bias)/sudo_klf_top_pdf_std_dic[m] for m in mass]\n",
    "hist, bin_edges = np.histogram(klf_top_pull, bins=np.arange(-5, 5, 0.2), density=True)\n",
    "popt, pcov = optimize.curve_fit(gau_norm, bin_edges[:-1]+0.1, hist)\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "plt.bar(bin_edges[:-1]+0.1, hist, edgecolor='b', width=0.2, color='None', label = 'Mean = {:.4f} ({:.4f}), std = {:.4f} ({:.4f})'.format(popt[0], perr[0], popt[1], perr[1]))\n",
    "plt.title('klfitter top mass pull histogram (sudo from pdf)')\n",
    "plt.xlim(-5, 5)\n",
    "plt.xlabel('top mass pull')\n",
    "plt.ylabel('Number')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
